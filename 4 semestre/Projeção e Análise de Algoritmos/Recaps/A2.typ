#import "@preview/ctheorems:1.1.3": *
#import "@preview/lovelace:0.3.0": *
#show: thmrules.with(qed-symbol: $square$)
#import "@preview/wrap-it:0.1.1"

#import "@preview/codly:1.3.0": *
#import "@preview/codly-languages:0.1.1": *
#show: codly-init.with()
#codly(languages: codly-languages, stroke: 1pt + luma(100))

#import "@preview/tablex:0.0.9": tablex, rowspanx, colspanx, cellx

#set page(width: 21cm, height: 30cm, margin: 1.5cm)

#set par(
  justify: true
)

#set figure(supplement: "Figura")

#set heading(numbering: "1.1.1")

#let theorem = thmbox("theorem", "Teorema")
#let corollary = thmplain(
  "corollary",
  "Corol√°rio",
  base: "theorem",
  titlefmt: strong
)
#let definition = thmbox("definition", "Defini√ß√£o", inset: (x: 1.2em, top: 1em))
#let example = thmplain("example", "Exemplo").with(numbering: none)
#let proof = thmproof("proof", "Demonstra√ß√£o")

#set math.equation(
  numbering: "(1)",
  supplement: none,
)
#show ref: it => {
  // provide custom reference for equations
  if it.element != none and it.element.func() == math.equation {
    // optional: wrap inside link, so whole label is linked
    link(it.target)[(#it)]
  } else {
    it
  }
}

#set text(
  font: "Atkinson Hyperlegible",
  size: 12pt,
)

#show heading: it => {
  if it.level == 1 {
    [
      #block(
        width: 100%,
        height: 1cm,
        text(
          size: 1.5em,
          weight: "bold",
          it.body
        )
      )
    ]
  } else {
    it
  }
}

// ============================ PRIMEIRA P√ÅGINA =============================
#align(center + top)[
  FGV EMAp

  Escrita:  Thalis Ambrosim Falqueto ]

#align(horizon + center)[
  #text(17pt)[
    Projeto e An√°lise de Algoritmos
  ]
  
  #text(14pt)[
    Revis√£o para A2
  ]
]

#align(bottom + center)[
  Rio de Janeiro

  2025
]

#pagebreak()

// ============================ P√ÅGINAS POSTERIORES =========================
#outline(title: "Conte√∫do")

#pagebreak()

#align(center + horizon)[
  = T√©cnicas de Projeto
]

#pagebreak()

== M√©todo guloso (Greedy)

O m√©todo guloso √© uma famoso paradigma utilizado para projetos de algoritmo, onde a estrat√©gia consiste em escolher a cada itera√ß√£o a op√ß√£o com maior valor, e avaliar se deve ser adicionada ao resultado final.

Seguindo essa abordagem, as op√ß√µes precisam ser ordenadas pro algum crit√©rio. Costuma ser simples e eficiente, por√©m nem todo projeto pode ser resolvido atrav√©s dessa abordagem.

=== O problema do agendamento de tarefas


 Dado o conjunto de tarefas $T = {t_1, t_2, ... ,t_n}$ com $n$ elementos, cada uma com tempo de √≠nicio ```start [tk]```, e um tempo de t√©rmino ```end [tk]```, encontre o maior subconjunto de tarefas que pode ser alocado sem sobreposi√ß√£o temporal.

#figure(
  caption: [Exemplo do problema de agendamento],
  image("images/agendamentoexample.png",width: 80%)
)


Vamos projetar a solu√ß√£o!

Perguntas: 
+ Quais ser√£o as op√ß√µes a serem avaliadas a cada itera√ß√£o? 
  - Conjunto de tarefas que ainda n√£o foi alocada ou descartada.
+ Qual crit√©rio iremos utilizar para ordenar as op√ß√µes? 
  - Tempo de √≠nicio?
  - Menor dura√ß√£o?
  - Menor n√∫mero de projetos?
  - Tempo de t√©rmino?

Vamos analisar cada crit√©rio tentando construir ao menos um cen√°rio que demonstre que o crit√©rio gera um resultado n√£o-√≥timo.

Que tal se colocarmos o crit√©rio de sele√ß√£o como o tempo de in√≠cio do agendamento?

#figure(
  caption: [Contra-exemplo para uma poss√≠vel solu√ß√£o do problema de agendamento],
  image("images/agendamentoexruim1.png",width: 80%)
)

Isso n√£o daria certo, pois nesse caso, por exemplo, o $t_5$ seria escolhido, enquanto a melhor escolha seria pegar as 4 primeiras tarefas.

E se escolhessemos pela menor dura√ß√£o?

#figure(
  caption: [Contra-exemplo para uma poss√≠vel solu√ß√£o do problema de agendamento],
  image("images/agendamento-ex-ruim-2.png",width: 80%)
)

Isso tamb√©m daria errado, j√° que escolher√≠amos $t_5, t_6 " e " t_7$ enquanto, novamente, a melhor escolha seriam os 4 primeiros.

Nada funcionou... Mas e se nosso crit√©rio fosse o tempo do t√©rmino?

Ideia geral:

#pseudocode-list[
+ *ordene* $T$ (pelo tempo de t√©rmino)
+ $T_a [1,...,n] = 0$ 
+ *Insira a primeira tarefa da lista* $t_0$ *em* $T_a$ 
+ $t_"prev" = t_0$
+ *para* $t_k$ *em* $T$:
  + *se* $"start"[t_k] >= "end"[t_"prev"]:$
    + *adicione* $t_k$ *em* $T_a$
    + $t_"prev" = t_k$
+ *retorne* $T_a$.
]

Essa ideia n√£o √© muito dif√≠cil. Como a lista √© ordenada pelo hor√°rio de sa√≠da, ent√£o o primeiro elemento a ser adicionado √© simplesmente o primeiro elemento. Note que, como o objetivo √© apenas a quantidade m√°xima de tarefas, e n√£o o tempo m√°ximo que podemos otimizar para todas as tarefas que temos, ent√£o pegar o menor t√©rmino *desde o in√≠cio* √© o que realmente faz o algoritmo funcionar (por exemplo, se tiv√©ssemos os hor√°rios `[(5,10),(5,12)]`,
pegar o menor tempo de sa√≠da nos ajudaria no caso de termos outra tarefa, como `(11,14)`). 

Ap√≥s selecionarmos a primeira tarefa da lista, basta compararmos os tempos de entrada das pr√≥ximas tarefas, j√° que, pelo mesmo racioc√≠nio do porque escolher a menor sa√≠da, se a pr√≥xima tarefa n√£o colidir com a sa√≠da passada, ent√£o podemos pegar nossa nova tarefa e atulizar com o tempo de sa√≠da da nova tarefa atual (como a lista est√° ordenada pelo tempo de fim, a nova tarefa a ser pega garantiria que seria a melhor tarefa, j√° que seria a primeira que se encaixa com o tempo de finaliza√ß√£o da √∫ltima tarefa selecionada e a mais curta j√° que estamos olhando por ordena√ß√£o).

Nosso pseudoc√≥digo usa apenas um for sem nada demais dentro dele, mas precisamos ordenar a lista antes. Isso nos traz uma complexidade de $Theta(n log(n))$.

#figure(
  grid(
  columns: 2,
  column-gutter: 1em,
  image("images/tarefa-example.png", width: 95%),
  image("images/tarefa-example-correta.png", width: 95%),
),
  caption: [Solu√ß√£o para o problema de tarefas usando o algoritmo proposto]
)

*Por que essa solu√ß√£o √© √≥tima?*

#definition[
  Escolha gulosa

  Uma solu√ß√£o √≥tima global pode ser atingida realizando uma sequ√™ncia de escolhas locais √≥timas (gulosas).
  - A escolha local n√£o considera o resultado das escolhas posteriores, e produz um sub-problema contendo um n√∫mero menor de elementos.
  - A defini√ß√£o do crit√©rio de escolha nos auxilia √† organizar os elementos de forma que o algortimo seja eficiente.
]
#definition[ Sub-estrutura √≥tima

Ocorre quando uma solu√ß√£o √≥tima de um problema apresenta dentro dela solu√ß√µes √≥timas para sub-problemas.
]

#definition[ Swap argument (Argumento de troca)

Considere que temos uma solu√ß√£o √≥tima $S$, e a solu√ß√£o gulosa $G$. Ent√£o √© poss√≠vel substituir iterativamente os elementos de $S$ por elementos de $G$ sem que a solu√ß√£o deixe de ser vi√°vel e √≥tima, provando assim que $G$ √©, no m√≠nimo, t√£o boa quanto $S$.  
]
Vamos usar o que aprendemos ent√£o:

Seja $T_a = {g_1, g_2, ..., g_k}$ o conjunto de $k$ tarefas selecionadas pelo nosso algoritmo guloso, j√° ordenadas pelo tempo de t√©rmino (como no pseudoc√≥digo).
Seja $S = {s_1, s_2, ..., s_m}$ uma _solu√ß√£o √≥tima_ qualquer, com $m$ tarefas, tamb√©m ordenadas por tempo de t√©rmino.

Nosso objetivo √© provar que $T_a$ √© √≥tima, ou seja, que $k = m$.

Queremos primeiro provar que a primeira escolha gulosa, $g_1$, pode fazer parte de _alguma_ solu√ß√£o √≥tima.

+ $g_1$ √© a tarefa escolhida por nosso algoritmo, ent√£o ela √© a tarefa em _todo_ o conjunto $T$ com o _menor tempo de t√©rmino_.
+ $s_1$ √© a primeira tarefa da solu√ß√£o √≥tima $S$. Ela tem o menor tempo de t√©rmino _dentro de $S$_.

Por defini√ß√£o, como $g_1$ tem o menor tempo de t√©rmino de _todas_ as tarefas, seu tempo de t√©rmino deve ser menor ou igual ao de $s_1$:

$ "end"[g_1] <= "end"[s_1] $

Agora, vamos comparar $g_1$ e $s_1$.

+ _Caso 1:_ $g_1 = s_1$.
  Se a primeira tarefa da solu√ß√£o √≥tima $S$ √© a mesma da solu√ß√£o gulosa $T_a$, ent√£o $S$ j√° come√ßa com a escolha gulosa.

+ _Caso 2:_ $g_1 != s_1$.
  Vamos "trocar" $s_1$ por $g_1$ na solu√ß√£o √≥tima $S$. Considere uma nova solu√ß√£o $S'$:
  $S' ={g_1, s_2, s_3, ..., s_m\} $
  Precisamos verificar se $S'$ ainda √© uma solu√ß√£o vi√°vel (sem sobreposi√ß√µes).
  - Como $S$ era uma solu√ß√£o vi√°vel, todas as suas tarefas eram compat√≠veis. Sabemos que $s_2$ devia come√ßar ap√≥s $s_1$ terminar: $"start"[s_2] >= "end"[s_1] $.
  - Mas, como vimos na Etapa 1, $"end"[g_1] <= "end"[s_1] $.
  - Combinando os fatos, temos que $"start"[s_2] >= "end"[g_1] $.
  - Isso significa que $g_1$ n√£o se sobrep√µe a $s_2$, e o resto das tarefas ($s_3, ...$) tamb√©m n√£o, pois j√° eram compat√≠veis com $s_2$.
  
A nova solu√ß√£o $S'$ √©, portanto, vi√°vel. O mais importante √© que $S'$ tem $m$ tarefas, o _mesmo tamanho_ da solu√ß√£o √≥tima $S$. Isso significa que $S'$ _tamb√©m √© uma solu√ß√£o √≥tima_.

Conclu√≠mos que _sempre_ existe uma solu√ß√£o √≥tima (seja $S$ ou $S'$) que come√ßa com a primeira escolha gulosa $g_1$.
Podemos repetir esse processo indutivamente. Em cada passo $i$, trocamos $s_i$ por $g_i$, transformando a solu√ß√£o √≥tima $S$ na solu√ß√£o gulosa $T_a$, sem nunca diminuir o n√∫mero de tarefas, usando sub-estruturas √≥timas.
Isso s√≥ √© poss√≠vel se as duas solu√ß√µes tiverem o mesmo tamanho desde o in√≠cio. Portanto, $k = m$.

Logo, a solu√ß√£o gulosa $T_a$ √©, de fato, uma solu√ß√£o √≥tima.

*Implementa√ß√£o em Python:*

```py
def scheduling_problem(tasks):  
    if len(tasks) == 0:                               #caso de contorno
        return 0

    sorted_by_end = sorted(tasks, key= lambda x:x[1]) #ordena pelo t√©rmino
    choosed_tasks = []
    choosed_tasks.append(sorted_by_end[0]) 
    t_prev = sorted_by_end[0]

    for task in sorted_by_end[1:]:                    #come√ßa depois da primeira
        if task[0] >= t_prev[1]:                      #tempo maior que o de sa√≠da
            choosed_tasks.append(task)
            t_prev = task
    return choosed_tasks, len(choosed_tasks)          #retorna lista, quantidade
```

=== O problema da mochila fracion√°ria

Dado um conjunto de itens $II = {1,2,3,...,n}$ em que cada item $i in II$ tem um peso $w_i$ e um valor $v_i$, e uma mochila com capacidade de peso $W$, encontre o subconjunto $S subset.eq II$ tal que $sum_(i in S)^(|S|) alpha_i w_i <= W $ e $sum_(i in S)^(|S|) alpha_i v_i $ seja m√°ximo, considerando que $0 < alpha_k <= 1$.

#figure(
  caption: [Tabela de exemplo para o exemplo da mochila],
  image("images/tabela-mochila.png",width: 40%)
)

#example[
  - W = 9
    - A escolha ${1,2,3}$ tem peso 8, valor 12 e cabe na mochila;
    - A escolha ${3,5}$ tem peso 11, valor 14 e *n√£o* cabe na mochila 
    - A escolha ${3_"50%", 5_"100%"}$ tem peso 9, valor 11 e cabe na mochila
    - A escolha ${1_"100%", 3_"75%", 4_"100%"}$ tem peso 9, valor 16.5 e cabe na mochila

]

Seria poss√≠vel criar um algoritmo capaz de encontrar uma solu√ß√£o √≥tima para esse problema?

- Pergunta 1: quais s√£o as op√ß√µes a serem avaliadas √† cada itera√ß√£o?
  - Itens (ou fragmentos de itens) que ainda n√£o foram adicionados ou descartados.
- Pergunta 2: Qual crit√©rio iremos utilizar para ordenar as op√ß√µes?
  - Menor peso? 
  - Menor valor?
  - Maior raz√£o peso/valor?

Essa ideia de raz√£o parece fazer sentido, j√° que podemos separar e  pegar a propor√ß√£o que quisermos. Da√≠ vem a ideia do algoritmo:

#pseudocode-list[

+ *Mochila* $ (I, v, w, n, W):$
  + *ordene* $I$ (pela raz√£o valor/peso)
  + $C, i = W, 1$
  + $M[1,...,n] = 0$
  + *enquanto* $i <= n " e " C >= w_i$:
    + $M[i] = 1$
    + $C = C - w_i$
    + $i += 1$
  + *se* $i <= n:$
    + $M[i] = C/w_i$
  - *retorne* $M $
]

Onde $I$ √© o conjunto de itens, $v$ o vetor de valores de cada item, $w$ o vetor de pesos de cada item, $n$ a quantidade de itens e $W$ √© a capacidade m√°xima da mochila.

Analisando brevemente, ordenamos *descrescentemente* o vetor de itens $II$, e declaramos a vari√°vel $C$, de capacidade, e $i$, de √≠ndice. Criamos o vetor de zeros $M$ (de tamanho $n$), que √© o vetor de porcentagem, referente a cada item. Note que como estamos ordenando pela propor√ß√£o de valor por peso decrescentemente, pegar o primeiro item significa pegar o que item que mais vale a pena. Logo, o while serve para, enquanto couber a capacidade, pegara maior quantidade poss√≠vel de valores. Quando o while quebra (no √≠ndice $i$), o algoritmo verifica se n√£o chegou ao final, e, caso n√£o tenha chegado, pega a propor√ß√£o m√°xima da capacidade m√°xima restante sobre o peso, e retorna a lista de pesos ao final.

O mais complexo √© a ordena√ß√£o, que pode ser garantido com $Theta(n log(n))$. 

*Implementa√ß√£o em Python:*

```py 
def fractional_bag_problem(I, v, w, max_w):
  n = len(I)                            #as tr√™s listas t√™m o mesmo tamanho   
  idx_w_ratio = []
  for i in range(n):
      ratio = v[i]/w[i]
      idx_w_ratio.append((i, w[i], ratio))#lista que armazena o √≠ndice, peso e raz√£o
                                        #ordena por raz√£o logo abaixo
  idx_w_ratio = sorted(idx_w_ratio, key = lambda x: x[2], reverse=True)
  capacity, i = max_w, 0
  M = [0] * n

  while i < n and capacity >= idx_w_ratio[i][1]: 
      M[i] = 1                          #faz o while normal 
      capacity -= idx_w_ratio[i][1]
      i += 1
  if i < n:
      M[i] = capacity/idx_w_ratio[i][1]
  
  itens_choosed = [0] * n               #lista que referencia a cada item a sua 
  for j in range(n):                    #porcentagem escolhida
      if M[j] != 0:
          itens_choosed[idx_w_ratio[j][0]] = M[j]
    
  return itens_choosed                  #retorna a lista de √≠ndices com a %
```

== Dividir e Conquistar

O nome j√° diz muito, e esse paradigma √© dividido em tr√™s etapas:

#wrap-it.wrap-content(
  
  figure(
    
    image("images/divide-and-conquer.png", width: 100%),
    
  ),
  [
    - Dividir o problema em um conjunto de sub-problemas menores.


    - Resolver cada sub-problema recursivamente.

  
    - Combinar os resultados de cada sub-problema gerando a solu√ß√£o.
    #v(6.5em)

    Figura 6: Exemplifica√ß√£o do paradigma Dividir e Conquistar. 
  ],
)

=== O problema de contagem de invers√µes 

Dado um problema com $n$ n√∫meros, calcule o n√∫mero de invers√µes necess√°rio para torn√°-la ordenada.

#example[
  
  Considere a sequ√™ncia `A = [3,7,2,9,5]`

  O n√∫mero de invers√µes √© 4: `(7,2),(3,2),(9,5),(7,5)`
]

A solu√ß√£o por for√ßa bruta seria verificar todos os pares, exigindo $Theta(n^2)$.

A solu√ß√£o baseada em dividir e conquistar dever√° definir estrat√©gias para resolver cada sub-problema do n√∫mero de invers√µes, e depois juntar, claro. Podemos dividir a sequ√™ncia em dois grupos com aproximadamente metade (O primeiro array at√© $n/2$, o segundo de $n/2 + 1$ at√© $n$). Essa opera√ß√£o √© constante, portanto $O(1)$.

A estrat√©gia de resolu√ß√£o deve contar o n√∫mero de invers√µes de cada grupo:
#example[
#figure(
  caption: [Exemplo do problema da contagem de invers√µes],
  image("images/divide-and-conquer-example.png",width: 75%)
)

Esse resultado pode ser obtido executando o algoritmo recursivamente ($~ T(n/2)$). Claro que, por fim, teremos que contar as invers√µes da jun√ß√£o das duas listas: 

#figure(
  image("images/divide-and-conquer-example2.png",width: 40%)
)

Totalizando, assim, 18 invers√µes.
]

Ok, a ideia est√° concisa, mas como fazer essa jun√ß√£o? Se ordenarmos cada segmento, e "juntarmos" direto, conseguir√≠amos fazer isso de forma f√°cil. Voltemos ao exemplo ap√≥s ordenar:

#figure(
  image("images/divide-and-conquer-example3.png",width: 70%)
)

Para a contagem de invers√µes para a jun√ß√£o, considere a sequ√™ncias √† esquerda de $L$ e √† direita de $R$ e defina $i = 0$.

#pseudocode-list[
+ *para* $a_j$ *de* $R$:
  + *incremente* $i$ *at√©* $L[i] > a_j$
  + $"inv"_"aj"$ $= |L| - i$.
]

Com $"inv"_"aj"$ sendo a quantidade de invers√µes do elemento $a_j$ de $R$.

Para explicar, considere o exemplo da imagem anterior e relembre um pouco do algoritmo de ordena√ß√£o MergeSort. Dado que as listas menores j√° est√£o ordenadas, se colocarmos um ponteiro no in√≠cio de cada lista, digamos `l` e `r`, ent√£o basta verificar se $L[l] <= R[r]$, e incrementarmos $l$(ou $r$, dependendo da compara√ß√£o).

Vamos continuar o exemplo (√† princ√≠pio, pense que apenas juntamos as duas listas): 
  - Para `l = 0` e `r = 0`, temos $1 <= 3$, que √© verdade. Incrementamos o `l`.
  - Para `l = 1` e `r = 0`, temos $2 <= 3$, que ainda √© verdade. Incrementamos o `l`.
  - Para `l = 2` e `r = 0`, temos $4 <= 3$, que √© mentira. Ent√£o, podemos aplicar o racioc√≠nio: sabendo que todos os elementos ap√≥s o $4$, como est√£o ordenados, s√£o maiores ou iguais a $4$ e, portanto, tamb√©m teriam que ser considerados como maiores do que 3, ent√£o do √≠nidice $l$ atual at√© $|L|$, uma invers√£o precisaria ser feita, se concaten√°ssemos as duas listas. Logo, temos $|L| - l$ trocas a serem feitas a partir de $L[l]$. Isso explica o algoritmo para a contagem de invers√µes para a jun√ß√£o.

  Agora que resolvemos esse problema, podemos desenhar o algoritmo final:

#pseudocode-list[
+ *CountInversions* $(A):$
  + *se* $"len(A)" = 1:$
    + *retorne* $0$
  + *divida a lista em* $L$ e $R$
  + $i_l = "CountInversions"(L)$
  + $i_r = "CountInversions"(R)$
  + $L = "Sort"(L)$
  + $R = "Sort(R)"$
  + $i = "Combine (L, R)"$

  + *retorne* $i_l + i_r + i $
]

Avaliando a complexidade desse algoritmo, temos:

$
  T(n) = 2 T(n/2) + O (n log(n)) = O(n (log(n))^2)
$

O $O(n log(n))$ vem da ordena√ß√£o das duas listas, e o $2 T(n/2)$ das duas listas que separamos. Os m√©todos de complexidade aprendidos na A1 nos levam a uma solu√ß√£o simples de $O(n(log(n))^2)$, j√° que sabemos que essa divis√£o pela metade traz um peso de $log(n)$.

Seria poss√≠vel trazer uma otimiza√ß√£o ainda maior? Sim, se eliminassemos a etapa de ordena√ß√£o expl√≠cita. Podemos fazer isso se, no algoritmo de contagem de invers√£o, al√©m de contar, invertessemos e realizassemos o merge, trazendo o array ordenado direto.

Novo algoritmo:

#pseudocode-list[

+ *CountInversions* $(A):$
  + *se* $"len(A)" = 1:$
    + *retorne* $0, A$
  + *divida a lista em* $L$ e $R$
  + $i_l , L= "CountInversions"(L)$
  + $i_r , R= "CountInversions"(R)$
  + $i = "Combine (L, R)"$
  + $A = "Merge"(L,R)$

  + *retorne* $(i_l + i_r + i), A $
]

Aqui, n√≥s nos aproveitamos da recurs√£o para fazer a ordena√ß√£o, em vez de fazer isso por outro algoritmo. Dado que a recurs√£o vai at√© quando s√≥ tivermos um elemento, e que sempre fazemos um merge, a lista est√° garantidamente sempre ordenada. Isso permite a execu√ß√£o do Combine sem problemas.

A fun√ß√£o Combine √© $O(n)$, j√° que apenas conta a quantidade de invers√µes que precisar√≠amos. A fun√ß√£o Merge tamb√©m √© $O(n)$, j√° que apenas junta as duas listas. Portanto, temos:

$
  T(n) = 2 T(n/2) + O(n) = n log(n)
$

*Implementa√ß√£o em python*

Para essa implementa√ß√£o, vamos relembrar basicamente a fun√ß√£o MergeSort, s√≥ que contando a quantidade de invers√µes. Ainda, vamos juntar as fun√ß√µes CountInversions e a Merge numa mesma.  
```py
def combine_merge(v, start_a, start_b, end_b):
    r = [0] * (end_b - start_a)
    a_idx = start_a
    b_idx = start_b
    r_idx = 0
    num_inv = 0                         #adicionado
    
    while a_idx < start_b and b_idx < end_b:
        if v[a_idx] <= v[b_idx]:
            r[r_idx] = v[a_idx]
            a_idx += 1
        else:
            num_inv += start_b - a_idx  #adicionado (explicado anteriormente)
            r[r_idx] = v[b_idx]
            b_idx += 1
        r_idx += 1
        
    while a_idx < start_b:
        r[r_idx] = v[a_idx]
        a_idx += 1
        r_idx += 1
        
    while b_idx < end_b:
        r[r_idx] = v[b_idx]
        b_idx += 1
        r_idx += 1
        
    for i in range(len(r)):
        v[start_a + i] = r[i]

    return num_inv                      #adicionado

def count_inversions(v, start_idx, end_idx):
    if (end_idx - start_idx) > 1:
        mid_idx = (start_idx + end_idx) // 2
        il = count_inversions(v, start_idx, mid_idx)      #essas linhas mudaram 
        ir = count_inversions(v, mid_idx, end_idx)        #apenas a igualdade
        
        i = combine_merge(v, start_idx, mid_idx, end_idx) #antes n√£o tinha
      return il + ir + i                #adicionado
    else:
      return 0  
```
Todo o c√≥digo (a menos de linhas comentadas) foi tirado da vers√£o original do MergeSort. Como dito, fizemos o MergeSort contando a quantidade de invers√µes. :)
=== O problema de pares mais pr√≥ximos

Dado uma sequ√™ncia com n pontos em um plano, encontre o par com a menor dist√¢ncia euclidiana.

#wrap-it.wrap-content(
  
  figure(
    image("images/divide-and-conquer-example4.png", width: 100%),
    
  ),
  [
     A primeira solu√ß√£o que vem a cabe√ßa √© simplesmente testar cada par com cada outro par, trazendo uma complexidade de $O(n^2)$

     Como desenvolver uma solu√ß√£o melhor com o m√©todo que aprendemos?
    
    #v(2em)
     Figura 10: Exemplifica√ß√£o do problema de pares mais pr√≥ximos
  ],
)

#grid(
  columns: (1fr, 1fr), 
  gutter: 1.5em,       
  [

    Podemos dividir o plano de forma que cada lado tenha aproximadamente o mesmo n√∫mero de pontos (ordenando pelo eixo x).

    Em seguida, resolva cada lado encontrando o par mais pr√≥ximo recursivamente.  
  
    #v(1.5em)
    Figura 11: Exemplifica√ß√£o da solu√ß√£o do problema de pares mais pr√≥ximos
  ],

  [
    #image("images/divide-and-conquer-example5.png", width: 100%)
  ]
)

Com o plano dividido, combine os resultados comparando O par mais pr√≥ximo no lado direito, o par mais pr√≥ximo do lado esquerdo, e o par mais pr√≥ximo em cada lado. A √∫ltima compara√ß√£o parece exigir $Theta(n^2)$, n√£o parece muito bom.

Se pensarmos apenas na compara√ß√£o da divis√£o dos planos, sejam $delta_l$ e $delta_r$ os pares com menor dist√¢ncia nos lados esquerdo e direito, respectivamente.

#wrap-it.wrap-content(
  
  figure(
    image("images/divide-and-conquer-example6.png", width: 100%),
    caption: "Exemplo da dist√¢ncia de compara√ß√£o."
    
  ),
  [
    Como estamos procurando o par mais pr√≥ximo, seja $delta_"min" <= min(delta_l, delta_r)$ (sabemos que $delta_"min"$ est√° restrito a, no m√°ximo, essa dist√¢ncia).

    Ideia: procurar somente os pontos que estejam no m√°ximo √† $delta_min$ da divis√≥ria, ordenando os pontos na faixa $2 delta_min$ pela posi√ß√£o o eixo y. 

    Qual seria a complexidade desse algoritmo?
  ],
)

Bom, n√£o seria $O(n^2)$, pois a dist√¢ncia em cada lado √© no m√≠nimo $delta_min$.

=== como faz isso cara como √© 11 7, 5 sla

=== Implementa√ß√£o em Python

== Programa√ß√£o Din√¢mica

O paradigma de programa√ß√£o din√¢mica consiste em quebrar em sub-problemas menores e resolv√™-los de forma independente. Semelhante ao dividir e conquistar, por√©m com foco em sub-problemas que usam repeti√ß√£o. Nessa t√©cnica, um sub-problema s√≥ √© resolvido caso n√£o tenha sido resolvido antes (caso contr√°rio √© usado o resultado anterior guardado previamente).

=== O problema de Fibonacci

#wrap-it.wrap-content(
  
  figure(
    image("images/dynamic-programming-example.png", width: 89%),
    caption: [Exemplo de como seria $"fib"(6)$]
    
  ),
  [
    Dado um inteiro $n >= 1$, encontre $F_n$. Solu√ß√£o recursiva (e ineficiente):

    ```py
    def fib(n):
      if n <= 2:
        return 1
      return fib(n-1) + fib(n-2)
    ```
  ],
)

Note como, para $n$, o tempo de execu√ß√£o √© exponencial, e que, grande parte dos problemas s√£o re-computados. Podemos utilizar um cach√™ para reaproveitar resultados. Vamos fazer isso!

#grid(
  columns: (1fr, 0.8fr), 
  gutter: 1.5em,       
  [
    
Solu√ß√£o Top-Down (recursiva):


    ```py
    def Fib(n):
      if n == 0:
          return 0
      if n == 1:
          return 1

      F = [-1] * (n + 1)
      F[0], F[1], F[2] = 0,1,1

      def FibAux(k):
        if F[k] == -1:
          F[k] = FibAux(k - 1) + FibAux(k-2)
        return F[k]

      return FibAux(n)
    ```
  ],

  [
    #figure(
    image("images/dynamic-programming-example2.png", width: 100%),
    caption: [Exemplo de como fica o cach√™ para $"Fib"(6)$]
    )
  ]
)

A complexidade desse algoritmo √© $Theta(n)$, sabendo que usamos apenas a lista para guardar os valores da lista de Fibonacci. 

Solu√ß√£o Bottom-Up (interativa):

```py
def Fib(n):
  if n <= 2:
      return 1
  F = [0] * n
  F[1], F[2] = 1, 1
  for i in range (3,n + 1,1):
      F[i] = F[i - 1] + F[i - 2]
  return F[n]
```

A complexidade √© a mesma da recursiva, desde que continuamos usando apenas um for e usando-a para guardar apenas uma lista.

A abordagem Top-Down √© recursiva, somente executa a recurs√£o caso o sub-problema n√£o tenha sido resolvido e inicia no problema maior, enquanto em problemas Bottom-Up a solu√ß√£o √© iterativa e resolve os sub-problemas do menor para o  maior. Al√©m disso, em geral apresentam a mesma complexidade.

=== O problema da mochila (n√£o fracion√°ria)

Dado um conjunto de itens $II = {1,2,3,...,n}$ em que cada item $i in II$ tem um peso $w_i$ e um valor $v_i$, e uma mochila com capacidade de peso $W$, encontre o subconjunto $S subset.eq II$ tal que $sum_(i in S)^(|S|) w_i <= W$ e $sum_(i in S)^(|S|) v_i$ seja m√°ximo.

A diferen√ßa desse problema para o que vimos no paradigma Guloso √© que agora, n√£o podemos pegar uma fra√ß√£o do item, apenas ou o pegamos ou n√£o. Isso faz com que, agora, por mais que o item seja o mais valoroso poss√≠vel na propor√ß√£o valor/peso, ainda assim possa existir alguma outra combina√ß√£o que tenha um valor maior.



#grid(
  columns: (1fr, 1fr), 
  gutter: 1.5em,       
  [
    Exemplo:

    W = 11

    A escolha ${1,2,4}$ tem peso 9, valor 29 e cabe na mochila.

    A escolha ${3,5}$ tem peso 12, valor 46 e n√£o cabe na mochila.
  ],

  [
    #figure(
    image("images/dynamic-programming-example3.png", width: 80%),
    caption: [Tabela auxiliar para exemplo]
    )
  ]
)

Solu√ß√£o(ineficiente): criar um algoritmo de for√ßa bruta que testa todas as possibilidades e escolhe a que cabe na mochila com maior valor.

Tentando usar o que estamos aprendendo aqui (programa√ß√£o din√¢mica), temos: 
- para cada item  $i$, considere a possibilidade de adicion√°-lo ou n√£o a mochila;
  - se adiconado, o valor √© incrementado de $v_i$ e a capacidade √© reduzida de $w_i$
  - avalie qual o melhor valor obtido em cada caso.
Ap√≥s considerar esse item, restam $n-1$ itens dispon√≠veis para serem avaliados (encontramos a sub-estrutura √≥tima).

Ideia geral (sem cach√™):

#pseudocode-list[

+ *Mochila* $ (I, v, w, W):$
  + *se* $|I| = 0$ *ou* $W = 0$
    +   *retorne* 0
  + *escolha* um item $i in I$
  + *se* $w_i > W:$
    + *retorne Mochila* $ (I - i, v, w, W):$
  + $"value_using" = v_i +$ *Mochila* $(I - i, v, w, W - w_i)$
  + $"value_not_using" = $ *Mochila* $(I - i, v, w, W)$
  + *retorna* $max{"value_using", "value_not_using"}$
]

Vamos para as solu√ß√µes definitivas, usando o paradigma que estamos aprendendo. A ideia, como temos que fazer uma compara√ß√£o a cada item que podemos pegar com e sem ele, √© usar uma matriz $I "x" W$, onde o valor de cada c√©lula $M[i][w]$ responde a seguinte pergunta: Qual √© o valor m√°ximo que consigo obter usando apenas os itens de 1 at√© $i$, com uma mochila de capacidade m√°xima $w$ (n√£o $W$).



#grid(
  columns: (1fr, 1fr), 
  gutter: 1.5em,       
  [
    Solu√ß√£o Top-Down:

  #pseudocode-list[

  + *Mochila* $ (n, v, w, W):$
    + *crie* uma matriz $n "x" W$
    + *para* $i = 0 $ *at√©* $W$:
      + $M[0][i] = 0$
      + *para* $j = 1$ *at√©* $n$:
        + $M[j][0] = 0$
        + $M[j][i] = -1$
    + *retorna MocilhaAux*$(n,v,w,W)$
  ]

  onde $n$ √© o total de itens. 

  Continua√ß√£o da solu√ß√£o:
  ],

  [
    #figure(
    image("images/dynamic-programming-example4.png", width: 80%),
    caption: [Exemplo da matriz para o algoritmo Top-Down e valores anteriores.]
    )
  ]
)

#pseudocode-list[

+ *MochilaAux* $ (i, v, w, W):$
  + *se* $M[i][W] = -1$:
    + *se* $w_i > W$:
      + $M[i][W] =$ *MochilaAux* $(i - 1, v, w, W)$
    + *caso contr√°rio*:
      + $"using" =v_i +$ *MochilaAux* $(i - 1,v,w,W - w_i)$
      + $"not_using" = $ *MochilaAux* $(i -1, v ,w ,W)$
      + $M[i][W] = max{"using,not_using"}$
  + *retorna* $M[i][W ]$
]

Onde $i$ √© o item que estamos considerando no momento. Essa solu√ß√£o usa a ideia explicada anteriormente, de fazer a verifica√ß√£o entre o melhor caso, adicionando e n√£o adicionando. Vamos agora para a solu√ß√£o Bottom-Up:


#pseudocode-list[

+ *Mochila* $ (n, v, w, W):$
  + *crie* uma matriz $n "x" W$
  + *para* $i = 0 $ *at√©* $W$:
    + $M[0][i] = 0$
  + *para* $j = 1$ *at√©* $n$:
    + $M[j][0] = 0$
  + *para* $j = 1$ *at√©* $n$:
    + *para* $i = 1$ *at√©* $W$:
      + *se* $w_j > i:$
        + $M[j][i] = M[j-1][i]$
      + *caso contr√°rio*:
        + $"using" =v_j + M[j -1][i - w_j]$ 
        + $"not_using" = M[j - 1][i]$ 
        + $M[j][i] = max{"using,not_using"}$
  + *retorna* $M[n][W]$
]

Sabendo que toda a an√°lise e o algoritmo √© baseado na cria√ß√£o da matriz, onde dentro da cria√ß√£o de cada item acontecem apenas verifica√ß√µes, ent√£o a complexidade $Theta(n W)$ (o que *n√£o* √© polinomial, j√° que $W$ √© um tamanho, n√£o um valor). Vamos ver agora como essa matriz ficaria no final:

#figure(
image("images/dynamic-programming-example5.png", width: 90%),
caption: [Resultado final da matriz finalizando o primeiro exemplo da mochila fracion√°ria.]
)

Lembre qual a fun√ß√£o da matriz: o √≠ndice $i$ (na linha) representa que podemos pegar qualquer dos itens $1$ at√© $i$, e o peso $W$ (na coluna) √© o peso $w$ que foi escolhido, e o n√∫mero no √≠ndice $n "x" w$ √© o valor que conseguimos nessa combina√ß√£o. Portanto, podemos interpretar que, na segunda linha, na coluna de $w = 0$, temos $0$ itens para ser colocados e podemos colocar at√© um peso $0$, logo, o valor m√°ximo √© 0. Ao continuar dessa linha, conseguimos ver que, a partir de quando o peso fica $>= 1$, conseguimos colocar o √∫nico item liberado ($1$), com peso $1$ e valor $1$. Por isso, toda a segunda linha √© igual a $1$ a partir do momento que $w >= 1$.

*Nota:* Seguindo esse racioc√≠nio, voc√™, caro leitor, pode verificar cada valor da tabela. Existe *um* erro na tabela. Convido a voc√™ interpret√°-la e entend√™-l√° e encontrar o erro. Se quiser validar que encontrou o erro, mande uma mensagem (Thalis).

Para finalizar, precisamos definir quais itens devem ser adicionados √† mochila:


#wrap-it.wrap-content(
  columns: (1.375fr, 1fr),
  figure(
    image("images/dynamic-programming-example6.png", width: 100%),
    caption: [Exemplo da busca dos itens adicionados (as c√©lulas pintadas de laranja s√£o as c√©lulas visitadas pelo algoritmo)]
    
  ),
  [
    #pseudocode-list[
    + $S, i, j = {}, W, n$
    + *enquanto* $j >= 1$:
      + *se* $M[j][i] = M[j-1][i - w_j] + v_j$
        + $S = S union {j}$
        + $i = i - w_j$
      + $j = j -1$
    + *retorna* $S$ 
    ]
  ],
)

Vamos entender o c√≥digo: $j$ itera nas linhas, W nas colunas. Em teoria, a √∫ltima c√©lula da matriz ($n "x" W$) carrega com certeza o maior valor que satisfaz a condi√ß√£o do problema, e por isso come√ßamos por ela. O que estamos fazendo √© verificar se $M[j][i] = M[j-1][i - w_j] + v_j$, ou seja, se o valor da c√©lula voltando o peso do item atual (supondo que ele foi adicionado) e voltando um item ($j - 1$) somado ao valor de $v_j$ √© igual ao valor da c√©lula atual, pois, se isso for verdade, significa que adicionamos esse valor ao descobrir o item $j$.

Vamos olhar para o exemplo da tabela:
- Ponto de partida: $M[5][11]$. Valor $= 40$. O item 5 (peso 7, valor 28) foi usado para obter esse valor de 40?
  - Comparamos o valor atual ($M[5][11]=40$) com o valor da c√©lula de cima ($M[4][4]=7 + v_j = 7 + 28 != 40$).
  - Como os valores n√£o s√£o iguais, significa que o item 5 *n√£o* foi inclu√≠do. A solu√ß√£o √≥tima para capacidade 11 j√° existia sem ele.
  - Ent√£o o algoritmo "sobe" para a c√©lula $M[4][11]$. 

- Posi√ß√£o Atual: C√©lula $M[4][11]$. Valor $= 40$. O item 4 (peso 6, valor 22) foi usado?
  -  Comparamos o valor atual ($M[4][11]=40$) com o valor da c√©lula de cima ($M[3][5]=18 + v_j = 18 + 22 = 40 $).
  - Os valores s√£o iguais. Isso significa que o item 4 *foi* inclu√≠do!
  - Adicionamos o item 4 ao nosso conjunto de solu√ß√£o $S$.O algoritmo "sobe" para a linha anterior ($i=3$) e "anda para a esquerda" subtraindo o peso do item 4 da capacidade: $11 - 6 = 5$. O novo ponto de an√°lise √© $M[3][5]$ .

E assim sucessivamente!

*Implementa√ß√£o em Python*

```py
def bag_problem_bottom_up(n, v, w, W):
  #primeira parte (criar a matriz e inserir os valores)
  M = [[0] * (W + 1) for _ in range(n + 1)]
  for j in range(1, n + 1):
      for i in range(1, W + 1):
          peso_item_j = w[j-1]
          valor_item_j = v[j-1]          
          if peso_item_j > i:
              M[j][i] = M[j - 1][i]
          else:
              not_using = M[j - 1][i]
              using = valor_item_j + M[j - 1][i - peso_item_j]
              M[j][i] = max(using, not_using)
                
  #segunda parte (identificar os itens selecionados)
  itens_selecionados = []
  valor_maximo = M[n][W]
  j, i = n, W
  while j > 0 and i > 0:
      peso_item_j = w[j-1]
      valor_item_j = v[j-1]
      if peso_item_j <= i and M[j][i] == (M[j- 1][i - peso_item_j] + valor_item_j):
          itens_selecionados.append(j)
          i -= peso_item_j
          j -= 1
  itens_selecionados.reverse()
  return valor_maximo, M, itens_selecionados
```
Convido o caro leitor a implementar a solu√ß√£o Top-Down. 



#pagebreak()

#align(center + horizon)[
  = Grafos
]

#pagebreak()

Sinceramente, fazer uma revis√£o de conceitos muito b√°sicos de grafos que j√° vimos em Matem√°tica Discreta √© um pouco chato, para n√£o dizer
desnecess√°rio. Irei relembrar alguns termos e definir outros que n√£o me lembro de termos vistos. Vamos l√°:

== Relembrando conceitos

- $V ->$ v√©rtices;
- $E ->$ arestas;
- Uma aresta √© definida pelo par $(v_i, v_j)$;
- O *tamanho* de um grafo √© definido por $|V| + |E|$, onde $|.|$ √© a cardinalidade (quantidade de elementos);

- Dado $e = (v_i, v_j)$, $v_i$ e $v_j$ s√£o *extremos* da aresta se $e$ √© incidente em $v_i$ e $v_j$, e $v_i$ e $v_j$ √© incidente em $e$;
- V√©rtices relacionados por uma aresta s√£o *adjacentes*;
- Duas arestas s√£o *paralelas* se incidem ao mesmo v√©rtice;
- *La√ßo* $= (v_i,v_i)$;
- $sum_(i = 1)^(|V|) g(v_i) = 2 |E|$, onde $g(v_i)$ √© o *grau* do v√©rtice $i$;
- Um grafo √© *completo* se cada v√©rtice possuir todos os demais adjacentes √† ele;
- O n√∫mero de arestas em um grafo completo √© definido por: $(|V|(|V| - 1))/2$ (observe que isso √© ligeiramente menor que $(|V|)^2/2 $;
- Um grafo √© *regular* se todos os v√©rtices possu√≠rem o mesmo grau (ou $k$-regular , para grau $k$);
- O n√∫mero de arestas em um grafo $k$-regular √© $|V|k/2$
- Um grafo √© *denso* se o seu tamanho for proporcional ao quadrado do n√∫mero de v√©rtices ($|V| + |E| prop |V|^2$), e √© esparso se $(|V| + |E|) prop |V|$.
- O grafo $H = G(V', E')$ √© um *subgrafo* de $G = (V, E)$ se $V' subset.eq V$ e $E' subset.eq E$.
- O grafo $H = G(V', E')$ √© um *subgrafo gerador* de $G = (V, E)$ se $H$ for um subgrafo de $G$ e $V' =  V$.
- O grafo $H = G(V', E')$ √© um *grafo induzido* de $G = (V, E)$ se $E'$ for definido por todas as arestas de $E$ adjacentes a um par de v√©rtices $V'$.
- O grafo $H = G(V', E')$ √© um *grafo pr√≥prio* de $G = (V, E)$ se $H subset G$.
- Um *caminho* $P$ em $G(V, E)$ consiste em uma sequ√™ncia de $n$ v√©rtices, finita e n√£o vazia tal que $v_(i+1)$ √© adjacente a $v_i$.
- Um caminho √© *simples* se n√£o possuir v√©rtices repetidos.  
- Um caminho √© *fechado* se $v_1 = v_n$.
- O *comprimento* de um caminho √© definido pelo n√∫mero de arestas do caminho.
- Um grafo $G = (V,E)$ √© *conexo* se para qualquer par de v√©rtices existe um caminho em $G$.
- Quando um grafo n√£o √© conexo podemos segment√°-lo em *componentes conexos* (um par est√° no mesmo componente se existe um caminho).
- Um grafo $G(V,E)$ √© uma *√°rvore* se $G$ for conexo e ac√≠clico (possui $|V| - 1$ arestas, a remo√ß√£o de qualquer aresta torna o grafo n√£o-conexo e para todo par de v√©rtices existe um √∫nico caminho);
- Um grafo $G(V,E)$ √© uma *floresta* se for um grafo ac√≠clico;
- Um grafo √© *planar* se puder ser representado graficamente em um plano de tal forma que n√£o haja cruzamento de arestas;
- Um grafo $G(V,E)$ √© *bipartido* se os v√©rtices puderem ser divididos em dois conjuntos $V_1$ e $V_2$ de forma que toda aresta $e_k$ √© incidente em $(v_i, v_j)$ tal que $v_i in V_1$ e $v_j in V_2$;
- Um grafo $G(V,E)$ √© *orientado* se as arestas possuirem um sentido. Nesse caso, a nomenclatura que definimos $(v_i,v_j)$ significa que ela come√ßa em $v_i$ e termina em $v_j$.
- O grau de *s√°ida* $g_s (v_i)$ √© definido pelo n√∫mero de arestas que saem de $v_i$. Racioc√≠no an√°logo para grau de *entrada* $g_e (v_i)$;
- $sum_(i = 1)^(|V|)  g_e (v_i) = sum_(i = 1)^(|V|) g_s (v_i) = |E|$;
- O v√©rtice $v_i$ √© uma *fonte* se $g_e (v_i) = 0$;
- O v√©rtice $v_i$ √© um *sorvedouro* se $g_s (v_i) = 0$;
- O v√©rtice  $v_i$ √© *isolado* se for sorvedouro e fonte;
- Um grafo (orientado ou n√£o) √© *ponderado* se cada aresta estiver associado a um peso;

== Estruturas de dados para representar grafos

Dependendo do problema, a escolha da estrutura pode variar, e, em geral, usamos duas formas de implementar essa representa√ß√£o:

=== Matriz de adjac√™ncia

Consiste em um matriz quadrada $A$ de ordem $|V|$ cujas linhas e colunas s√£o indexadas pelos v√©rtices de $V$. Exemplo para grafos orienteados:

#figure(
    image("images/graph-structure1.png", width: 90%),
    caption: [Exemplo de matriz de adjac√™ncia para o grafo √† direita. ]
    
)

Analogamente, para n√£o orientados:

#figure(
    image("images/graph-structure2.png", width: 90%),
    caption: [Exemplo de matriz de adjac√™ncia para o grafo √† direita. Nota: a matriz √© sim√©trica! ]
)

A complexidade de acessar(ou verificar) uma aresta √© $Theta(1)$, e claramente conta com uma complexidade de espa√ßo de $Theta(|V|^2)$. Al√©m disso, o fato da matriz ser sim√©trica para grafos n√£o-orientados faz com que o tamanho se reduza para a metade, podendo se armazenar apenas a diagonal superior ou inferior da matriz.

=== c√≥digo da implementa√ß√£o 

=== Lista de adjac√™ncia

Consiste em uma sequ√™ncia de v√©rtices contendo na estrutura de cada ponteiro para uma lista encadeada com elemento representando as arestas adjacentes ao v√©rtices. Exemplo para grafo dirigido:


#figure(
    image("images/graph-structure3.png", width: 95%),
    caption: [Exemplo da lista de adjac√™ncia para o grafo √† direita.]
)

Exemplo para grafo n√£o-dirigido:

#figure(
    image("images/graph-structure4.png", width: 95%),
    caption: [Exemplo da lista de adjac√™ncia para o grafo √† direita.]
)

A complexidade de acessar o conjunto de arestas de um v√©rtice √© $Theta(1)$ (mas encontrar uma aresta espec√≠fica √© $Theta(|V|)$ no pior caso).


ma lista de adjac√™ncia exige um espa√ßo Œò( ùëâ + |ùê∏|)

As estruturas de dados do v√©rtice e da aresta podem ser estendidas para armazenar
informa√ß√µes espec√≠ficas do problema.

